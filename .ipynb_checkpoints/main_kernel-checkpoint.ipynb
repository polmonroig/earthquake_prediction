{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LANL Earthquake Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data:\n",
    "\n",
    "To get the data, we only have to download it from the database and open it, altough there was to much data, thus, I splitted the data into 4196 csv files of 150000 rows each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "\n",
    "# define constants\n",
    "DATA_DIR = \"data/\"\n",
    "TRAIN_DIR = \"data/train/\"\n",
    "TEST_DIR = \"\"\n",
    "\n",
    "# load data into dataframe\n",
    "train_files = os.listdir(TRAIN_DIR);\n",
    "train_files.sort()\n",
    "LANL_train_set = pd.read_csv(os.path.join(TRAIN_DIR, train_files[42]))\n",
    "LANL_train_array = np.array(LANL_train_set['acoustic_data'])\n",
    "LANL_train_labels = np.array(LANL_train_set['time_to_failure'])\n",
    "LANL_mean = np.mean(LANL_train_array)\n",
    "LANL_std  = np.std(LANL_train_array)\n",
    "LANL_variance = np.var(LANL_train_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analize Data:\n",
    "\n",
    "First of all, lets plot the head of the data into our notebook, tyo see an example of what we are working with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acoustic_data</th>\n",
       "      <th>time_to_failure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>11.3737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>11.3737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>11.3737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>11.3737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>11.3737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acoustic_data  time_to_failure\n",
       "0              8          11.3737\n",
       "1              8          11.3737\n",
       "2              3          11.3737\n",
       "3              3          11.3737\n",
       "4              1          11.3737"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LANL_train_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's plot all the acoustic data to have a more visual representation of it. For this, I made a function that generates different plots we can use such as an histogram and a boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_plots(x):\n",
    "    n_bins = 70\n",
    "    rows = 3\n",
    "    cols = 1\n",
    "    plt.figure(1, figsize=(7, 15))\n",
    "    # plot data\n",
    "    plt.subplot(rows, cols, 1)\n",
    "    plt.plot(x)\n",
    "    \n",
    "    # plot histogram\n",
    "    hist = plt.subplot(rows, cols, 2)\n",
    "    hist.set_title(\"Histogram\")\n",
    "    n, bins, patches = plt.hist(x, n_bins, facecolor='orange', alpha=0.5)\n",
    "    \n",
    "    # plot boxplot\n",
    "    boxplot = plt.subplot(rows, cols, 3)\n",
    "    plt.boxplot(x)\n",
    "    boxplot.set_title(\"Boxplot\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we generate the different plots, we can see form the histogram that the instance follows a normal distribution and the most of the values are positive, this may vary from instance to instace, altought all of them a similar distribition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x1080 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gen_plots(LANL_train_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data we are using right represents only a single intance wich is a time segment with only one label. With this instance we might neeed to do some feature engeneering. Let's see some example of qualities we can get from the instance and its label. From this data, I concluded that we can use the mean of all the failure times from the instance as the single label for the instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:  4.3839733333333335\n",
      "Standard deviation:  4.22277844702066\n",
      "Variance:  17.83185781262222\n",
      "Time to failure mean:  11.354673242272735\n",
      "Max time to failure:  11.373699597\n",
      "Min time to failure:  11.335396800000002\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean: \", LANL_mean)\n",
    "print(\"Standard deviation: \", LANL_std)\n",
    "print(\"Variance: \", LANL_variance)\n",
    "print(\"Time to failure mean: \", np.mean(LANL_train_labels))\n",
    "print(\"Max time to failure: \", np.max(LANL_train_labels))\n",
    "print(\"Min time to failure: \", np.min(LANL_train_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see we are starting to make new features for this instance, let's save it in a pandas dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.array([LANL_mean, LANL_std, LANL_variance])\n",
    "LANL_train = pd.DataFrame({'mean' : [features[0]], 'deviation' : [features[1]], 'variance' : features[2]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>deviation</th>\n",
       "      <th>variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.383973</td>\n",
       "      <td>4.222778</td>\n",
       "      <td>17.831858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean  deviation   variance\n",
       "0  4.383973   4.222778  17.831858"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LANL_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a nice way to store all the features for each instance. But it seems a bit deorganized and once we start adding functions and features it will get more complicated; so let's make a simple pipeline to automatize all the process. For this I created a list of functions to make each feature and an estimator that applies each function to the instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "cv =  lambda x: np.std(x) / np.mean(x)\n",
    "\n",
    "# feature functions\n",
    "feature_names = ['mean', 'deviation', 'variance', \n",
    "                 'min', 'max', 'skewness',\n",
    "                 'kurtosis', 'quantile_25', 'quantile_50',\n",
    "                 'quantile_75', 'coeficient__of_variation']\n",
    "feature_trans = {'mean' : np.mean, 'deviation' : np.std, 'variance' : np.var, \n",
    "                 'min' : np.min, 'max' : np.max, 'skewness' : skew,\n",
    "                 'kurtosis' : kurtosis, 'quantile' : np.percentile, 'coeficient__of_variation' : cv}\n",
    "\n",
    "class FeatureGenerator(BaseEstimator, TransformerMixin):\n",
    "   \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        features = []\n",
    "        for name in feature_trans:\n",
    "            if name == 'quantile':\n",
    "                features.append(feature_trans[name](X, 25))\n",
    "                features.append(feature_trans[name](X, 50))\n",
    "                features.append(feature_trans[name](X, 75))\n",
    "            else:\n",
    "                features.append(feature_trans[name](X))\n",
    "        return np.c_[features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's generate the features for all the instances in the dataset. The following function automates all the process from getting the data, appaying the function and finally normalazing it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def GetTrainInstances(max_inst=-1, directory=TRAIN_DIR, normalize=True):\n",
    "    LANL_X = []\n",
    "    LANL_y = []\n",
    "    i = 0\n",
    "\n",
    "    gen = FeatureGenerator()\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    max_instances = max_inst\n",
    "    for file in train_files:\n",
    "        if i == max_instances:\n",
    "            break\n",
    "        tmp = pd.read_csv(os.path.join(directory, file))\n",
    "        tmp_data = np.array(tmp['acoustic_data'])\n",
    "        tmp_labels = np.array(tmp['time_to_failure'])\n",
    "        LANL_X.append(gen.fit_transform(tmp_data))\n",
    "        # for all time instances we get the mean\n",
    "        LANL_y.append(np.mean(tmp_labels)) \n",
    "        i += 1\n",
    "    if normalize:\n",
    "        LANL_X = scaler.fit_transform(np.array(LANL_X).reshape(max_instances, len(feature_names)))\n",
    "    LANL_X = pd.DataFrame(np.array(LANL_X).reshape(max_instances, len(feature_names)), columns=feature_names)\n",
    "    LANL_y = pd.DataFrame(np.array(LANL_y).reshape(max_instances, 1), columns=['time_to_failure'])\n",
    "    LANL_X.to_csv(os.path.join(DATA_DIR, \"train_data.csv\"), sep=',', encoding='utf-8', index=False)\n",
    "    LANL_y.to_csv(os.path.join(DATA_DIR, \"train_labels.csv\"), sep=',', encoding='utf-8', index=False)\n",
    "    return LANL_X, LANL_y\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANL_X, LANL_y = GetTrainInstances(max_inst=-1, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also load the dataset that has been generated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANL_X = pd.read_csv(os.path.join(DATA_DIR, \"train_data_01.csv\"))\n",
    "LANL_y = pd.read_csv(os.path.join(DATA_DIR, \"train_labels_01.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now I only loaded 200 instances of the dataset because it is easier to work with. When we start training the model I will include all the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>deviation</th>\n",
       "      <th>variance</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>skewness</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>quantile_25</th>\n",
       "      <th>quantile_50</th>\n",
       "      <th>quantile_75</th>\n",
       "      <th>coeficient__of_variation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.424262</td>\n",
       "      <td>-0.170139</td>\n",
       "      <td>-0.080570</td>\n",
       "      <td>0.193132</td>\n",
       "      <td>-0.218112</td>\n",
       "      <td>-0.313682</td>\n",
       "      <td>-0.491116</td>\n",
       "      <td>1.593643</td>\n",
       "      <td>0.946823</td>\n",
       "      <td>0.288785</td>\n",
       "      <td>-0.217288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.805767</td>\n",
       "      <td>0.004826</td>\n",
       "      <td>-0.064853</td>\n",
       "      <td>-0.018144</td>\n",
       "      <td>0.064045</td>\n",
       "      <td>0.554010</td>\n",
       "      <td>0.431916</td>\n",
       "      <td>-0.406157</td>\n",
       "      <td>0.946823</td>\n",
       "      <td>0.288785</td>\n",
       "      <td>-0.030956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.511287</td>\n",
       "      <td>0.049349</td>\n",
       "      <td>-0.060215</td>\n",
       "      <td>0.162950</td>\n",
       "      <td>-0.086194</td>\n",
       "      <td>0.191611</td>\n",
       "      <td>-0.492637</td>\n",
       "      <td>-0.406157</td>\n",
       "      <td>0.946823</td>\n",
       "      <td>0.288785</td>\n",
       "      <td>-0.017197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.495064</td>\n",
       "      <td>0.044046</td>\n",
       "      <td>-0.060781</td>\n",
       "      <td>-0.187919</td>\n",
       "      <td>0.122675</td>\n",
       "      <td>1.321450</td>\n",
       "      <td>0.684165</td>\n",
       "      <td>-0.406157</td>\n",
       "      <td>0.946823</td>\n",
       "      <td>0.288785</td>\n",
       "      <td>-0.021455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.520375</td>\n",
       "      <td>0.088596</td>\n",
       "      <td>-0.055912</td>\n",
       "      <td>0.087494</td>\n",
       "      <td>-0.067873</td>\n",
       "      <td>-0.128283</td>\n",
       "      <td>-0.217232</td>\n",
       "      <td>-0.406157</td>\n",
       "      <td>0.946823</td>\n",
       "      <td>0.288785</td>\n",
       "      <td>0.018658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.539098</td>\n",
       "      <td>-0.130976</td>\n",
       "      <td>-0.077399</td>\n",
       "      <td>0.019584</td>\n",
       "      <td>-0.078866</td>\n",
       "      <td>-0.474060</td>\n",
       "      <td>-0.256406</td>\n",
       "      <td>1.593643</td>\n",
       "      <td>0.946823</td>\n",
       "      <td>0.288785</td>\n",
       "      <td>-0.184515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.313125</td>\n",
       "      <td>-0.101138</td>\n",
       "      <td>-0.074849</td>\n",
       "      <td>0.268588</td>\n",
       "      <td>-0.159482</td>\n",
       "      <td>0.173654</td>\n",
       "      <td>-0.639852</td>\n",
       "      <td>-0.406157</td>\n",
       "      <td>0.946823</td>\n",
       "      <td>0.288785</td>\n",
       "      <td>-0.149664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.054873</td>\n",
       "      <td>-0.081534</td>\n",
       "      <td>-0.073111</td>\n",
       "      <td>0.057312</td>\n",
       "      <td>-0.089859</td>\n",
       "      <td>-0.632347</td>\n",
       "      <td>-0.225586</td>\n",
       "      <td>-0.406157</td>\n",
       "      <td>0.946823</td>\n",
       "      <td>0.288785</td>\n",
       "      <td>-0.081452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.774779</td>\n",
       "      <td>0.146050</td>\n",
       "      <td>-0.049249</td>\n",
       "      <td>-0.025689</td>\n",
       "      <td>0.016408</td>\n",
       "      <td>-0.598514</td>\n",
       "      <td>-0.041656</td>\n",
       "      <td>-0.406157</td>\n",
       "      <td>0.946823</td>\n",
       "      <td>0.288785</td>\n",
       "      <td>0.105872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.826051</td>\n",
       "      <td>0.040300</td>\n",
       "      <td>-0.061178</td>\n",
       "      <td>0.087494</td>\n",
       "      <td>-0.042222</td>\n",
       "      <td>0.052211</td>\n",
       "      <td>-0.206139</td>\n",
       "      <td>-0.406157</td>\n",
       "      <td>0.946823</td>\n",
       "      <td>0.288785</td>\n",
       "      <td>0.002191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.247631</td>\n",
       "      <td>-0.045927</td>\n",
       "      <td>-0.069824</td>\n",
       "      <td>0.128995</td>\n",
       "      <td>0.298565</td>\n",
       "      <td>3.028507</td>\n",
       "      <td>0.697154</td>\n",
       "      <td>-0.406157</td>\n",
       "      <td>0.946823</td>\n",
       "      <td>0.288785</td>\n",
       "      <td>-0.057959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.740343</td>\n",
       "      <td>1.023908</td>\n",
       "      <td>0.106199</td>\n",
       "      <td>-1.240525</td>\n",
       "      <td>0.903187</td>\n",
       "      <td>-1.715895</td>\n",
       "      <td>1.822406</td>\n",
       "      <td>-0.406157</td>\n",
       "      <td>-1.056164</td>\n",
       "      <td>0.288785</td>\n",
       "      <td>1.102933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.216528</td>\n",
       "      <td>0.248469</td>\n",
       "      <td>-0.036302</td>\n",
       "      <td>-0.074735</td>\n",
       "      <td>0.221613</td>\n",
       "      <td>-0.592758</td>\n",
       "      <td>-0.013944</td>\n",
       "      <td>-0.406157</td>\n",
       "      <td>-1.056164</td>\n",
       "      <td>0.288785</td>\n",
       "      <td>0.259790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.630181</td>\n",
       "      <td>-0.060502</td>\n",
       "      <td>-0.071189</td>\n",
       "      <td>0.076176</td>\n",
       "      <td>-0.089859</td>\n",
       "      <td>0.117249</td>\n",
       "      <td>-0.366470</td>\n",
       "      <td>-0.406157</td>\n",
       "      <td>0.946823</td>\n",
       "      <td>0.288785</td>\n",
       "      <td>-0.087036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.301715</td>\n",
       "      <td>-0.134747</td>\n",
       "      <td>-0.077713</td>\n",
       "      <td>0.091267</td>\n",
       "      <td>-0.240098</td>\n",
       "      <td>-1.095856</td>\n",
       "      <td>-0.383444</td>\n",
       "      <td>-0.406157</td>\n",
       "      <td>0.946823</td>\n",
       "      <td>0.288785</td>\n",
       "      <td>-0.147631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.306533</td>\n",
       "      <td>-0.025789</td>\n",
       "      <td>-0.067892</td>\n",
       "      <td>0.121449</td>\n",
       "      <td>-0.137496</td>\n",
       "      <td>-0.879458</td>\n",
       "      <td>-0.425395</td>\n",
       "      <td>-0.406157</td>\n",
       "      <td>0.946823</td>\n",
       "      <td>0.288785</td>\n",
       "      <td>-0.040469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.023391</td>\n",
       "      <td>-0.007952</td>\n",
       "      <td>-0.066136</td>\n",
       "      <td>-0.048326</td>\n",
       "      <td>-0.067873</td>\n",
       "      <td>0.161960</td>\n",
       "      <td>-0.227786</td>\n",
       "      <td>-0.406157</td>\n",
       "      <td>0.946823</td>\n",
       "      <td>0.288785</td>\n",
       "      <td>-0.008849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.172781</td>\n",
       "      <td>-0.064645</td>\n",
       "      <td>-0.071572</td>\n",
       "      <td>0.110131</td>\n",
       "      <td>-0.229105</td>\n",
       "      <td>-0.644983</td>\n",
       "      <td>-0.483702</td>\n",
       "      <td>-0.406157</td>\n",
       "      <td>-1.056164</td>\n",
       "      <td>0.288785</td>\n",
       "      <td>-0.059691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.042386</td>\n",
       "      <td>0.033376</td>\n",
       "      <td>-0.061908</td>\n",
       "      <td>0.121449</td>\n",
       "      <td>-0.159482</td>\n",
       "      <td>-0.179905</td>\n",
       "      <td>-0.528930</td>\n",
       "      <td>-0.406157</td>\n",
       "      <td>0.946823</td>\n",
       "      <td>0.288785</td>\n",
       "      <td>0.029626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.108697</td>\n",
       "      <td>0.088254</td>\n",
       "      <td>-0.055950</td>\n",
       "      <td>-0.150191</td>\n",
       "      <td>-0.086194</td>\n",
       "      <td>-0.358249</td>\n",
       "      <td>-0.321459</td>\n",
       "      <td>-0.406157</td>\n",
       "      <td>-1.056164</td>\n",
       "      <td>0.288785</td>\n",
       "      <td>0.091881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.392244</td>\n",
       "      <td>0.134274</td>\n",
       "      <td>-0.050650</td>\n",
       "      <td>0.098813</td>\n",
       "      <td>-0.064208</td>\n",
       "      <td>-0.034886</td>\n",
       "      <td>-0.341854</td>\n",
       "      <td>-0.406157</td>\n",
       "      <td>-1.056164</td>\n",
       "      <td>0.288785</td>\n",
       "      <td>0.153266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.533000</td>\n",
       "      <td>0.194588</td>\n",
       "      <td>-0.043284</td>\n",
       "      <td>-0.384103</td>\n",
       "      <td>0.239935</td>\n",
       "      <td>-1.168310</td>\n",
       "      <td>0.317376</td>\n",
       "      <td>-0.406157</td>\n",
       "      <td>0.946823</td>\n",
       "      <td>0.288785</td>\n",
       "      <td>0.164782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.023923</td>\n",
       "      <td>0.838597</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>-1.681940</td>\n",
       "      <td>0.547742</td>\n",
       "      <td>-5.286125</td>\n",
       "      <td>2.694686</td>\n",
       "      <td>-0.406157</td>\n",
       "      <td>0.946823</td>\n",
       "      <td>0.288785</td>\n",
       "      <td>0.836338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.116821</td>\n",
       "      <td>-0.103610</td>\n",
       "      <td>-0.075065</td>\n",
       "      <td>0.325180</td>\n",
       "      <td>-0.203455</td>\n",
       "      <td>0.144401</td>\n",
       "      <td>-0.703808</td>\n",
       "      <td>-0.406157</td>\n",
       "      <td>-1.056164</td>\n",
       "      <td>0.288785</td>\n",
       "      <td>-0.101278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.475805</td>\n",
       "      <td>-0.146043</td>\n",
       "      <td>-0.078643</td>\n",
       "      <td>0.238406</td>\n",
       "      <td>-0.291400</td>\n",
       "      <td>-0.210357</td>\n",
       "      <td>-0.707805</td>\n",
       "      <td>-0.406157</td>\n",
       "      <td>-1.056164</td>\n",
       "      <td>0.288785</td>\n",
       "      <td>-0.130930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.001101</td>\n",
       "      <td>0.008854</td>\n",
       "      <td>-0.064444</td>\n",
       "      <td>0.178041</td>\n",
       "      <td>-0.177804</td>\n",
       "      <td>-0.022398</td>\n",
       "      <td>-0.485323</td>\n",
       "      <td>-0.406157</td>\n",
       "      <td>0.946823</td>\n",
       "      <td>0.288785</td>\n",
       "      <td>0.007028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.701399</td>\n",
       "      <td>-0.015101</td>\n",
       "      <td>-0.066845</td>\n",
       "      <td>0.162950</td>\n",
       "      <td>-0.119174</td>\n",
       "      <td>-0.247022</td>\n",
       "      <td>-0.353219</td>\n",
       "      <td>-0.406157</td>\n",
       "      <td>0.946823</td>\n",
       "      <td>0.288785</td>\n",
       "      <td>-0.045940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.494580</td>\n",
       "      <td>-0.086343</td>\n",
       "      <td>-0.073542</td>\n",
       "      <td>0.170496</td>\n",
       "      <td>-0.166811</td>\n",
       "      <td>-0.394766</td>\n",
       "      <td>-0.483259</td>\n",
       "      <td>-0.406157</td>\n",
       "      <td>-1.056164</td>\n",
       "      <td>0.288785</td>\n",
       "      <td>-0.068673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.378845</td>\n",
       "      <td>0.023562</td>\n",
       "      <td>-0.062933</td>\n",
       "      <td>-0.086054</td>\n",
       "      <td>0.111682</td>\n",
       "      <td>0.071336</td>\n",
       "      <td>0.482630</td>\n",
       "      <td>-0.406157</td>\n",
       "      <td>0.946823</td>\n",
       "      <td>0.288785</td>\n",
       "      <td>0.005010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.219939</td>\n",
       "      <td>15.401375</td>\n",
       "      <td>16.983323</td>\n",
       "      <td>-16.871161</td>\n",
       "      <td>11.317342</td>\n",
       "      <td>-2.068989</td>\n",
       "      <td>2.208526</td>\n",
       "      <td>-2.405957</td>\n",
       "      <td>-1.056164</td>\n",
       "      <td>2.388355</td>\n",
       "      <td>15.637314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4165</th>\n",
       "      <td>1.403535</td>\n",
       "      <td>-0.126695</td>\n",
       "      <td>-0.077041</td>\n",
       "      <td>0.053539</td>\n",
       "      <td>-0.133831</td>\n",
       "      <td>0.174880</td>\n",
       "      <td>0.269832</td>\n",
       "      <td>1.593643</td>\n",
       "      <td>0.946823</td>\n",
       "      <td>0.288785</td>\n",
       "      <td>-0.176351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4166</th>\n",
       "      <td>1.422466</td>\n",
       "      <td>-0.360834</td>\n",
       "      <td>-0.093144</td>\n",
       "      <td>0.427045</td>\n",
       "      <td>-0.430646</td>\n",
       "      <td>-0.256508</td>\n",
       "      <td>-0.826506</td>\n",
       "      <td>1.593643</td>\n",
       "      <td>0.946823</td>\n",
       "      <td>0.288785</td>\n",
       "      <td>-0.394091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4167</th>\n",
       "      <td>0.724601</td>\n",
       "      <td>-0.231476</td>\n",
       "      <td>-0.085133</td>\n",
       "      <td>0.181814</td>\n",
       "      <td>-0.100852</td>\n",
       "      <td>1.152132</td>\n",
       "      <td>0.143385</td>\n",
       "      <td>1.593643</td>\n",
       "      <td>0.946823</td>\n",
       "      <td>0.288785</td>\n",
       "      <td>-0.255152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4168</th>\n",
       "      <td>0.433502</td>\n",
       "      <td>-0.222629</td>\n",
       "      <td>-0.084505</td>\n",
       "      <td>0.106358</td>\n",
       "      <td>-0.100852</td>\n",
       "      <td>0.955273</td>\n",
       "      <td>0.310132</td>\n",
       "      <td>1.593643</td>\n",
       "      <td>0.946823</td>\n",
       "      <td>0.288785</td>\n",
       "      <td>-0.238154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4169</th>\n",
       "      <td>0.982394</td>\n",
       "      <td>-0.393085</td>\n",
       "      <td>-0.094801</td>\n",
       "      <td>0.423272</td>\n",
       "      <td>-0.463625</td>\n",
       "      <td>-0.376689</td>\n",
       "      <td>-0.897264</td>\n",
       "      <td>1.593643</td>\n",
       "      <td>0.946823</td>\n",
       "      <td>0.288785</td>\n",
       "      <td>-0.415746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4170</th>\n",
       "      <td>0.440038</td>\n",
       "      <td>-0.371375</td>\n",
       "      <td>-0.093700</td>\n",
       "      <td>0.415726</td>\n",
       "      <td>-0.430646</td>\n",
       "      <td>-0.315044</td>\n",
       "      <td>-0.882943</td>\n",
       "      <td>1.593643</td>\n",
       "      <td>0.946823</td>\n",
       "      <td>0.288785</td>\n",
       "      <td>-0.383791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4171</th>\n",
       "      <td>0.818474</td>\n",
       "      <td>-0.230042</td>\n",
       "      <td>-0.085032</td>\n",
       "      <td>0.155404</td>\n",
       "      <td>-0.232770</td>\n",
       "      <td>-1.305194</td>\n",
       "      <td>-0.177095</td>\n",
       "      <td>1.593643</td>\n",
       "      <td>0.946823</td>\n",
       "      <td>0.288785</td>\n",
       "      <td>-0.256414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4172</th>\n",
       "      <td>0.099855</td>\n",
       "      <td>-0.331400</td>\n",
       "      <td>-0.091513</td>\n",
       "      <td>0.253497</td>\n",
       "      <td>-0.331708</td>\n",
       "      <td>-0.944365</td>\n",
       "      <td>-0.619785</td>\n",
       "      <td>1.593643</td>\n",
       "      <td>0.946823</td>\n",
       "      <td>0.288785</td>\n",
       "      <td>-0.336484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4173</th>\n",
       "      <td>0.998304</td>\n",
       "      <td>0.048243</td>\n",
       "      <td>-0.060333</td>\n",
       "      <td>-0.070962</td>\n",
       "      <td>-0.020236</td>\n",
       "      <td>-0.579045</td>\n",
       "      <td>0.471250</td>\n",
       "      <td>1.593643</td>\n",
       "      <td>0.946823</td>\n",
       "      <td>0.288785</td>\n",
       "      <td>0.002560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4174</th>\n",
       "      <td>0.838342</td>\n",
       "      <td>-0.310476</td>\n",
       "      <td>-0.090285</td>\n",
       "      <td>0.362907</td>\n",
       "      <td>-0.306057</td>\n",
       "      <td>-0.010545</td>\n",
       "      <td>-0.696471</td>\n",
       "      <td>1.593643</td>\n",
       "      <td>0.946823</td>\n",
       "      <td>0.288785</td>\n",
       "      <td>-0.333924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4175</th>\n",
       "      <td>0.993357</td>\n",
       "      <td>-0.295203</td>\n",
       "      <td>-0.089353</td>\n",
       "      <td>0.181814</td>\n",
       "      <td>-0.210783</td>\n",
       "      <td>-0.661674</td>\n",
       "      <td>0.125987</td>\n",
       "      <td>1.593643</td>\n",
       "      <td>0.946823</td>\n",
       "      <td>0.288785</td>\n",
       "      <td>-0.323088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4176</th>\n",
       "      <td>0.681140</td>\n",
       "      <td>-0.204963</td>\n",
       "      <td>-0.083221</td>\n",
       "      <td>0.211996</td>\n",
       "      <td>-0.170475</td>\n",
       "      <td>0.272734</td>\n",
       "      <td>-0.243828</td>\n",
       "      <td>1.593643</td>\n",
       "      <td>0.946823</td>\n",
       "      <td>0.288785</td>\n",
       "      <td>-0.228341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4177</th>\n",
       "      <td>0.976561</td>\n",
       "      <td>-0.196028</td>\n",
       "      <td>-0.082556</td>\n",
       "      <td>0.181814</td>\n",
       "      <td>-0.221776</td>\n",
       "      <td>0.048893</td>\n",
       "      <td>-0.265718</td>\n",
       "      <td>1.593643</td>\n",
       "      <td>0.946823</td>\n",
       "      <td>0.288785</td>\n",
       "      <td>-0.228502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4178</th>\n",
       "      <td>0.717075</td>\n",
       "      <td>-0.058385</td>\n",
       "      <td>-0.070993</td>\n",
       "      <td>-0.040780</td>\n",
       "      <td>-0.060544</td>\n",
       "      <td>-0.790992</td>\n",
       "      <td>0.066463</td>\n",
       "      <td>1.593643</td>\n",
       "      <td>0.946823</td>\n",
       "      <td>0.288785</td>\n",
       "      <td>-0.088245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4179</th>\n",
       "      <td>0.380538</td>\n",
       "      <td>-0.238450</td>\n",
       "      <td>-0.085620</td>\n",
       "      <td>0.276133</td>\n",
       "      <td>-0.276742</td>\n",
       "      <td>0.019778</td>\n",
       "      <td>-0.522034</td>\n",
       "      <td>-0.406157</td>\n",
       "      <td>0.946823</td>\n",
       "      <td>0.288785</td>\n",
       "      <td>-0.252102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4180</th>\n",
       "      <td>1.211075</td>\n",
       "      <td>-0.181032</td>\n",
       "      <td>-0.081416</td>\n",
       "      <td>0.106358</td>\n",
       "      <td>-0.170475</td>\n",
       "      <td>-0.217993</td>\n",
       "      <td>-0.017291</td>\n",
       "      <td>1.593643</td>\n",
       "      <td>0.946823</td>\n",
       "      <td>0.288785</td>\n",
       "      <td>-0.221216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4181</th>\n",
       "      <td>0.944480</td>\n",
       "      <td>-0.336019</td>\n",
       "      <td>-0.091777</td>\n",
       "      <td>0.381771</td>\n",
       "      <td>-0.383009</td>\n",
       "      <td>-0.141094</td>\n",
       "      <td>-0.758967</td>\n",
       "      <td>1.593643</td>\n",
       "      <td>0.946823</td>\n",
       "      <td>0.288785</td>\n",
       "      <td>-0.360732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4182</th>\n",
       "      <td>1.970758</td>\n",
       "      <td>-0.290305</td>\n",
       "      <td>-0.089047</td>\n",
       "      <td>0.276133</td>\n",
       "      <td>-0.331708</td>\n",
       "      <td>-0.092983</td>\n",
       "      <td>-0.665672</td>\n",
       "      <td>1.593643</td>\n",
       "      <td>0.946823</td>\n",
       "      <td>0.288785</td>\n",
       "      <td>-0.341112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4183</th>\n",
       "      <td>1.487903</td>\n",
       "      <td>-0.046961</td>\n",
       "      <td>-0.069922</td>\n",
       "      <td>0.072403</td>\n",
       "      <td>-0.108181</td>\n",
       "      <td>0.604788</td>\n",
       "      <td>0.156826</td>\n",
       "      <td>1.593643</td>\n",
       "      <td>0.946823</td>\n",
       "      <td>0.288785</td>\n",
       "      <td>-0.105288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4184</th>\n",
       "      <td>1.589849</td>\n",
       "      <td>-0.287222</td>\n",
       "      <td>-0.088853</td>\n",
       "      <td>0.291225</td>\n",
       "      <td>-0.309721</td>\n",
       "      <td>-0.098278</td>\n",
       "      <td>-0.507280</td>\n",
       "      <td>1.593643</td>\n",
       "      <td>0.946823</td>\n",
       "      <td>0.288785</td>\n",
       "      <td>-0.329717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4185</th>\n",
       "      <td>0.844227</td>\n",
       "      <td>-0.235362</td>\n",
       "      <td>-0.085405</td>\n",
       "      <td>0.268588</td>\n",
       "      <td>-0.247427</td>\n",
       "      <td>0.041815</td>\n",
       "      <td>-0.590791</td>\n",
       "      <td>1.593643</td>\n",
       "      <td>0.946823</td>\n",
       "      <td>0.288785</td>\n",
       "      <td>-0.262222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4186</th>\n",
       "      <td>1.025828</td>\n",
       "      <td>-0.203367</td>\n",
       "      <td>-0.083103</td>\n",
       "      <td>0.110131</td>\n",
       "      <td>-0.163146</td>\n",
       "      <td>-0.071623</td>\n",
       "      <td>-0.077698</td>\n",
       "      <td>1.593643</td>\n",
       "      <td>0.946823</td>\n",
       "      <td>0.288785</td>\n",
       "      <td>-0.236891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4187</th>\n",
       "      <td>0.765353</td>\n",
       "      <td>-0.101785</td>\n",
       "      <td>-0.074906</td>\n",
       "      <td>0.068630</td>\n",
       "      <td>0.104353</td>\n",
       "      <td>1.173154</td>\n",
       "      <td>0.130154</td>\n",
       "      <td>1.593643</td>\n",
       "      <td>0.946823</td>\n",
       "      <td>0.288785</td>\n",
       "      <td>-0.131729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4188</th>\n",
       "      <td>0.805116</td>\n",
       "      <td>-0.220637</td>\n",
       "      <td>-0.084362</td>\n",
       "      <td>0.057312</td>\n",
       "      <td>-0.188797</td>\n",
       "      <td>-1.331597</td>\n",
       "      <td>0.400626</td>\n",
       "      <td>1.593643</td>\n",
       "      <td>0.946823</td>\n",
       "      <td>0.288785</td>\n",
       "      <td>-0.247026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4189</th>\n",
       "      <td>0.266275</td>\n",
       "      <td>-0.260442</td>\n",
       "      <td>-0.087117</td>\n",
       "      <td>0.283679</td>\n",
       "      <td>-0.196126</td>\n",
       "      <td>0.092852</td>\n",
       "      <td>-0.563206</td>\n",
       "      <td>-0.406157</td>\n",
       "      <td>0.946823</td>\n",
       "      <td>0.288785</td>\n",
       "      <td>-0.270489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4190</th>\n",
       "      <td>0.363117</td>\n",
       "      <td>-0.283507</td>\n",
       "      <td>-0.088618</td>\n",
       "      <td>0.249724</td>\n",
       "      <td>-0.236434</td>\n",
       "      <td>0.033534</td>\n",
       "      <td>-0.300371</td>\n",
       "      <td>1.593643</td>\n",
       "      <td>0.946823</td>\n",
       "      <td>0.288785</td>\n",
       "      <td>-0.295843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4191</th>\n",
       "      <td>1.208679</td>\n",
       "      <td>-0.287242</td>\n",
       "      <td>-0.088855</td>\n",
       "      <td>0.313861</td>\n",
       "      <td>-0.309721</td>\n",
       "      <td>-0.646903</td>\n",
       "      <td>-0.430273</td>\n",
       "      <td>1.593643</td>\n",
       "      <td>0.946823</td>\n",
       "      <td>0.288785</td>\n",
       "      <td>-0.320765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4192</th>\n",
       "      <td>0.993383</td>\n",
       "      <td>-0.116682</td>\n",
       "      <td>-0.076192</td>\n",
       "      <td>0.004493</td>\n",
       "      <td>0.023737</td>\n",
       "      <td>-0.628855</td>\n",
       "      <td>0.622469</td>\n",
       "      <td>1.593643</td>\n",
       "      <td>0.946823</td>\n",
       "      <td>0.288785</td>\n",
       "      <td>-0.153713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4193</th>\n",
       "      <td>0.889224</td>\n",
       "      <td>-0.269446</td>\n",
       "      <td>-0.087711</td>\n",
       "      <td>0.310089</td>\n",
       "      <td>-0.320715</td>\n",
       "      <td>-0.286889</td>\n",
       "      <td>-0.567377</td>\n",
       "      <td>1.593643</td>\n",
       "      <td>0.946823</td>\n",
       "      <td>0.288785</td>\n",
       "      <td>-0.295984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4194</th>\n",
       "      <td>0.336426</td>\n",
       "      <td>-0.290450</td>\n",
       "      <td>-0.089056</td>\n",
       "      <td>0.279906</td>\n",
       "      <td>-0.328043</td>\n",
       "      <td>-0.123227</td>\n",
       "      <td>-0.640663</td>\n",
       "      <td>1.593643</td>\n",
       "      <td>0.946823</td>\n",
       "      <td>0.288785</td>\n",
       "      <td>-0.301962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4195 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          mean  deviation   variance        min        max  skewness  \\\n",
       "0     1.424262  -0.170139  -0.080570   0.193132  -0.218112 -0.313682   \n",
       "1     0.805767   0.004826  -0.064853  -0.018144   0.064045  0.554010   \n",
       "2     1.511287   0.049349  -0.060215   0.162950  -0.086194  0.191611   \n",
       "3     1.495064   0.044046  -0.060781  -0.187919   0.122675  1.321450   \n",
       "4     1.520375   0.088596  -0.055912   0.087494  -0.067873 -0.128283   \n",
       "5     1.539098  -0.130976  -0.077399   0.019584  -0.078866 -0.474060   \n",
       "6     1.313125  -0.101138  -0.074849   0.268588  -0.159482  0.173654   \n",
       "7    -0.054873  -0.081534  -0.073111   0.057312  -0.089859 -0.632347   \n",
       "8     0.774779   0.146050  -0.049249  -0.025689   0.016408 -0.598514   \n",
       "9     0.826051   0.040300  -0.061178   0.087494  -0.042222  0.052211   \n",
       "10    0.247631  -0.045927  -0.069824   0.128995   0.298565  3.028507   \n",
       "11   -0.740343   1.023908   0.106199  -1.240525   0.903187 -1.715895   \n",
       "12   -0.216528   0.248469  -0.036302  -0.074735   0.221613 -0.592758   \n",
       "13    0.630181  -0.060502  -0.071189   0.076176  -0.089859  0.117249   \n",
       "14    0.301715  -0.134747  -0.077713   0.091267  -0.240098 -1.095856   \n",
       "15    0.306533  -0.025789  -0.067892   0.121449  -0.137496 -0.879458   \n",
       "16   -0.023391  -0.007952  -0.066136  -0.048326  -0.067873  0.161960   \n",
       "17   -0.172781  -0.064645  -0.071572   0.110131  -0.229105 -0.644983   \n",
       "18    0.042386   0.033376  -0.061908   0.121449  -0.159482 -0.179905   \n",
       "19   -0.108697   0.088254  -0.055950  -0.150191  -0.086194 -0.358249   \n",
       "20   -0.392244   0.134274  -0.050650   0.098813  -0.064208 -0.034886   \n",
       "21    0.533000   0.194588  -0.043284  -0.384103   0.239935 -1.168310   \n",
       "22    0.023923   0.838597   0.065000  -1.681940   0.547742 -5.286125   \n",
       "23   -0.116821  -0.103610  -0.075065   0.325180  -0.203455  0.144401   \n",
       "24   -0.475805  -0.146043  -0.078643   0.238406  -0.291400 -0.210357   \n",
       "25   -0.001101   0.008854  -0.064444   0.178041  -0.177804 -0.022398   \n",
       "26    0.701399  -0.015101  -0.066845   0.162950  -0.119174 -0.247022   \n",
       "27   -0.494580  -0.086343  -0.073542   0.170496  -0.166811 -0.394766   \n",
       "28    0.378845   0.023562  -0.062933  -0.086054   0.111682  0.071336   \n",
       "29   -0.219939  15.401375  16.983323 -16.871161  11.317342 -2.068989   \n",
       "...        ...        ...        ...        ...        ...       ...   \n",
       "4165  1.403535  -0.126695  -0.077041   0.053539  -0.133831  0.174880   \n",
       "4166  1.422466  -0.360834  -0.093144   0.427045  -0.430646 -0.256508   \n",
       "4167  0.724601  -0.231476  -0.085133   0.181814  -0.100852  1.152132   \n",
       "4168  0.433502  -0.222629  -0.084505   0.106358  -0.100852  0.955273   \n",
       "4169  0.982394  -0.393085  -0.094801   0.423272  -0.463625 -0.376689   \n",
       "4170  0.440038  -0.371375  -0.093700   0.415726  -0.430646 -0.315044   \n",
       "4171  0.818474  -0.230042  -0.085032   0.155404  -0.232770 -1.305194   \n",
       "4172  0.099855  -0.331400  -0.091513   0.253497  -0.331708 -0.944365   \n",
       "4173  0.998304   0.048243  -0.060333  -0.070962  -0.020236 -0.579045   \n",
       "4174  0.838342  -0.310476  -0.090285   0.362907  -0.306057 -0.010545   \n",
       "4175  0.993357  -0.295203  -0.089353   0.181814  -0.210783 -0.661674   \n",
       "4176  0.681140  -0.204963  -0.083221   0.211996  -0.170475  0.272734   \n",
       "4177  0.976561  -0.196028  -0.082556   0.181814  -0.221776  0.048893   \n",
       "4178  0.717075  -0.058385  -0.070993  -0.040780  -0.060544 -0.790992   \n",
       "4179  0.380538  -0.238450  -0.085620   0.276133  -0.276742  0.019778   \n",
       "4180  1.211075  -0.181032  -0.081416   0.106358  -0.170475 -0.217993   \n",
       "4181  0.944480  -0.336019  -0.091777   0.381771  -0.383009 -0.141094   \n",
       "4182  1.970758  -0.290305  -0.089047   0.276133  -0.331708 -0.092983   \n",
       "4183  1.487903  -0.046961  -0.069922   0.072403  -0.108181  0.604788   \n",
       "4184  1.589849  -0.287222  -0.088853   0.291225  -0.309721 -0.098278   \n",
       "4185  0.844227  -0.235362  -0.085405   0.268588  -0.247427  0.041815   \n",
       "4186  1.025828  -0.203367  -0.083103   0.110131  -0.163146 -0.071623   \n",
       "4187  0.765353  -0.101785  -0.074906   0.068630   0.104353  1.173154   \n",
       "4188  0.805116  -0.220637  -0.084362   0.057312  -0.188797 -1.331597   \n",
       "4189  0.266275  -0.260442  -0.087117   0.283679  -0.196126  0.092852   \n",
       "4190  0.363117  -0.283507  -0.088618   0.249724  -0.236434  0.033534   \n",
       "4191  1.208679  -0.287242  -0.088855   0.313861  -0.309721 -0.646903   \n",
       "4192  0.993383  -0.116682  -0.076192   0.004493   0.023737 -0.628855   \n",
       "4193  0.889224  -0.269446  -0.087711   0.310089  -0.320715 -0.286889   \n",
       "4194  0.336426  -0.290450  -0.089056   0.279906  -0.328043 -0.123227   \n",
       "\n",
       "      kurtosis  quantile_25  quantile_50  quantile_75  \\\n",
       "0    -0.491116     1.593643     0.946823     0.288785   \n",
       "1     0.431916    -0.406157     0.946823     0.288785   \n",
       "2    -0.492637    -0.406157     0.946823     0.288785   \n",
       "3     0.684165    -0.406157     0.946823     0.288785   \n",
       "4    -0.217232    -0.406157     0.946823     0.288785   \n",
       "5    -0.256406     1.593643     0.946823     0.288785   \n",
       "6    -0.639852    -0.406157     0.946823     0.288785   \n",
       "7    -0.225586    -0.406157     0.946823     0.288785   \n",
       "8    -0.041656    -0.406157     0.946823     0.288785   \n",
       "9    -0.206139    -0.406157     0.946823     0.288785   \n",
       "10    0.697154    -0.406157     0.946823     0.288785   \n",
       "11    1.822406    -0.406157    -1.056164     0.288785   \n",
       "12   -0.013944    -0.406157    -1.056164     0.288785   \n",
       "13   -0.366470    -0.406157     0.946823     0.288785   \n",
       "14   -0.383444    -0.406157     0.946823     0.288785   \n",
       "15   -0.425395    -0.406157     0.946823     0.288785   \n",
       "16   -0.227786    -0.406157     0.946823     0.288785   \n",
       "17   -0.483702    -0.406157    -1.056164     0.288785   \n",
       "18   -0.528930    -0.406157     0.946823     0.288785   \n",
       "19   -0.321459    -0.406157    -1.056164     0.288785   \n",
       "20   -0.341854    -0.406157    -1.056164     0.288785   \n",
       "21    0.317376    -0.406157     0.946823     0.288785   \n",
       "22    2.694686    -0.406157     0.946823     0.288785   \n",
       "23   -0.703808    -0.406157    -1.056164     0.288785   \n",
       "24   -0.707805    -0.406157    -1.056164     0.288785   \n",
       "25   -0.485323    -0.406157     0.946823     0.288785   \n",
       "26   -0.353219    -0.406157     0.946823     0.288785   \n",
       "27   -0.483259    -0.406157    -1.056164     0.288785   \n",
       "28    0.482630    -0.406157     0.946823     0.288785   \n",
       "29    2.208526    -2.405957    -1.056164     2.388355   \n",
       "...        ...          ...          ...          ...   \n",
       "4165  0.269832     1.593643     0.946823     0.288785   \n",
       "4166 -0.826506     1.593643     0.946823     0.288785   \n",
       "4167  0.143385     1.593643     0.946823     0.288785   \n",
       "4168  0.310132     1.593643     0.946823     0.288785   \n",
       "4169 -0.897264     1.593643     0.946823     0.288785   \n",
       "4170 -0.882943     1.593643     0.946823     0.288785   \n",
       "4171 -0.177095     1.593643     0.946823     0.288785   \n",
       "4172 -0.619785     1.593643     0.946823     0.288785   \n",
       "4173  0.471250     1.593643     0.946823     0.288785   \n",
       "4174 -0.696471     1.593643     0.946823     0.288785   \n",
       "4175  0.125987     1.593643     0.946823     0.288785   \n",
       "4176 -0.243828     1.593643     0.946823     0.288785   \n",
       "4177 -0.265718     1.593643     0.946823     0.288785   \n",
       "4178  0.066463     1.593643     0.946823     0.288785   \n",
       "4179 -0.522034    -0.406157     0.946823     0.288785   \n",
       "4180 -0.017291     1.593643     0.946823     0.288785   \n",
       "4181 -0.758967     1.593643     0.946823     0.288785   \n",
       "4182 -0.665672     1.593643     0.946823     0.288785   \n",
       "4183  0.156826     1.593643     0.946823     0.288785   \n",
       "4184 -0.507280     1.593643     0.946823     0.288785   \n",
       "4185 -0.590791     1.593643     0.946823     0.288785   \n",
       "4186 -0.077698     1.593643     0.946823     0.288785   \n",
       "4187  0.130154     1.593643     0.946823     0.288785   \n",
       "4188  0.400626     1.593643     0.946823     0.288785   \n",
       "4189 -0.563206    -0.406157     0.946823     0.288785   \n",
       "4190 -0.300371     1.593643     0.946823     0.288785   \n",
       "4191 -0.430273     1.593643     0.946823     0.288785   \n",
       "4192  0.622469     1.593643     0.946823     0.288785   \n",
       "4193 -0.567377     1.593643     0.946823     0.288785   \n",
       "4194 -0.640663     1.593643     0.946823     0.288785   \n",
       "\n",
       "      coeficient__of_variation  \n",
       "0                    -0.217288  \n",
       "1                    -0.030956  \n",
       "2                    -0.017197  \n",
       "3                    -0.021455  \n",
       "4                     0.018658  \n",
       "5                    -0.184515  \n",
       "6                    -0.149664  \n",
       "7                    -0.081452  \n",
       "8                     0.105872  \n",
       "9                     0.002191  \n",
       "10                   -0.057959  \n",
       "11                    1.102933  \n",
       "12                    0.259790  \n",
       "13                   -0.087036  \n",
       "14                   -0.147631  \n",
       "15                   -0.040469  \n",
       "16                   -0.008849  \n",
       "17                   -0.059691  \n",
       "18                    0.029626  \n",
       "19                    0.091881  \n",
       "20                    0.153266  \n",
       "21                    0.164782  \n",
       "22                    0.836338  \n",
       "23                   -0.101278  \n",
       "24                   -0.130930  \n",
       "25                    0.007028  \n",
       "26                   -0.045940  \n",
       "27                   -0.068673  \n",
       "28                    0.005010  \n",
       "29                   15.637314  \n",
       "...                        ...  \n",
       "4165                 -0.176351  \n",
       "4166                 -0.394091  \n",
       "4167                 -0.255152  \n",
       "4168                 -0.238154  \n",
       "4169                 -0.415746  \n",
       "4170                 -0.383791  \n",
       "4171                 -0.256414  \n",
       "4172                 -0.336484  \n",
       "4173                  0.002560  \n",
       "4174                 -0.333924  \n",
       "4175                 -0.323088  \n",
       "4176                 -0.228341  \n",
       "4177                 -0.228502  \n",
       "4178                 -0.088245  \n",
       "4179                 -0.252102  \n",
       "4180                 -0.221216  \n",
       "4181                 -0.360732  \n",
       "4182                 -0.341112  \n",
       "4183                 -0.105288  \n",
       "4184                 -0.329717  \n",
       "4185                 -0.262222  \n",
       "4186                 -0.236891  \n",
       "4187                 -0.131729  \n",
       "4188                 -0.247026  \n",
       "4189                 -0.270489  \n",
       "4190                 -0.295843  \n",
       "4191                 -0.320765  \n",
       "4192                 -0.153713  \n",
       "4193                 -0.295984  \n",
       "4194                 -0.301962  \n",
       "\n",
       "[4195 rows x 11 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LANL_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try to find out more information about the dataset looking at the correlation of the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>deviation</th>\n",
       "      <th>variance</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>skewness</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>quantile_25</th>\n",
       "      <th>quantile_50</th>\n",
       "      <th>quantile_75</th>\n",
       "      <th>coeficient__of_variation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.075027</td>\n",
       "      <td>0.065674</td>\n",
       "      <td>-0.081726</td>\n",
       "      <td>0.073511</td>\n",
       "      <td>0.039009</td>\n",
       "      <td>0.107496</td>\n",
       "      <td>0.445906</td>\n",
       "      <td>0.801363</td>\n",
       "      <td>0.537295</td>\n",
       "      <td>0.043580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deviation</th>\n",
       "      <td>0.075027</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.970883</td>\n",
       "      <td>-0.982689</td>\n",
       "      <td>0.944820</td>\n",
       "      <td>0.239904</td>\n",
       "      <td>0.309859</td>\n",
       "      <td>-0.378055</td>\n",
       "      <td>0.032728</td>\n",
       "      <td>0.475736</td>\n",
       "      <td>0.999245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variance</th>\n",
       "      <td>0.065674</td>\n",
       "      <td>0.970883</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.930091</td>\n",
       "      <td>0.860018</td>\n",
       "      <td>0.195681</td>\n",
       "      <td>0.202585</td>\n",
       "      <td>-0.350086</td>\n",
       "      <td>0.047031</td>\n",
       "      <td>0.443746</td>\n",
       "      <td>0.965811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.081726</td>\n",
       "      <td>-0.982689</td>\n",
       "      <td>-0.930091</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.968294</td>\n",
       "      <td>-0.235444</td>\n",
       "      <td>-0.451237</td>\n",
       "      <td>0.354422</td>\n",
       "      <td>-0.040998</td>\n",
       "      <td>-0.451942</td>\n",
       "      <td>-0.983573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.073511</td>\n",
       "      <td>0.944820</td>\n",
       "      <td>0.860018</td>\n",
       "      <td>-0.968294</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.351226</td>\n",
       "      <td>0.460183</td>\n",
       "      <td>-0.294379</td>\n",
       "      <td>0.022891</td>\n",
       "      <td>0.381275</td>\n",
       "      <td>0.950184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skewness</th>\n",
       "      <td>0.039009</td>\n",
       "      <td>0.239904</td>\n",
       "      <td>0.195681</td>\n",
       "      <td>-0.235444</td>\n",
       "      <td>0.351226</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.260637</td>\n",
       "      <td>-0.027052</td>\n",
       "      <td>0.046493</td>\n",
       "      <td>0.040409</td>\n",
       "      <td>0.244670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kurtosis</th>\n",
       "      <td>0.107496</td>\n",
       "      <td>0.309859</td>\n",
       "      <td>0.202585</td>\n",
       "      <td>-0.451237</td>\n",
       "      <td>0.460183</td>\n",
       "      <td>0.260637</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.016196</td>\n",
       "      <td>0.116686</td>\n",
       "      <td>0.154731</td>\n",
       "      <td>0.313613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantile_25</th>\n",
       "      <td>0.445906</td>\n",
       "      <td>-0.378055</td>\n",
       "      <td>-0.350086</td>\n",
       "      <td>0.354422</td>\n",
       "      <td>-0.294379</td>\n",
       "      <td>-0.027052</td>\n",
       "      <td>-0.016196</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.452045</td>\n",
       "      <td>-0.070777</td>\n",
       "      <td>-0.388945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantile_50</th>\n",
       "      <td>0.801363</td>\n",
       "      <td>0.032728</td>\n",
       "      <td>0.047031</td>\n",
       "      <td>-0.040998</td>\n",
       "      <td>0.022891</td>\n",
       "      <td>0.046493</td>\n",
       "      <td>0.116686</td>\n",
       "      <td>0.452045</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.415262</td>\n",
       "      <td>0.005998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantile_75</th>\n",
       "      <td>0.537295</td>\n",
       "      <td>0.475736</td>\n",
       "      <td>0.443746</td>\n",
       "      <td>-0.451942</td>\n",
       "      <td>0.381275</td>\n",
       "      <td>0.040409</td>\n",
       "      <td>0.154731</td>\n",
       "      <td>-0.070777</td>\n",
       "      <td>0.415262</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.458700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coeficient__of_variation</th>\n",
       "      <td>0.043580</td>\n",
       "      <td>0.999245</td>\n",
       "      <td>0.965811</td>\n",
       "      <td>-0.983573</td>\n",
       "      <td>0.950184</td>\n",
       "      <td>0.244670</td>\n",
       "      <td>0.313613</td>\n",
       "      <td>-0.388945</td>\n",
       "      <td>0.005998</td>\n",
       "      <td>0.458700</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              mean  deviation  variance       min       max  \\\n",
       "mean                      1.000000   0.075027  0.065674 -0.081726  0.073511   \n",
       "deviation                 0.075027   1.000000  0.970883 -0.982689  0.944820   \n",
       "variance                  0.065674   0.970883  1.000000 -0.930091  0.860018   \n",
       "min                      -0.081726  -0.982689 -0.930091  1.000000 -0.968294   \n",
       "max                       0.073511   0.944820  0.860018 -0.968294  1.000000   \n",
       "skewness                  0.039009   0.239904  0.195681 -0.235444  0.351226   \n",
       "kurtosis                  0.107496   0.309859  0.202585 -0.451237  0.460183   \n",
       "quantile_25               0.445906  -0.378055 -0.350086  0.354422 -0.294379   \n",
       "quantile_50               0.801363   0.032728  0.047031 -0.040998  0.022891   \n",
       "quantile_75               0.537295   0.475736  0.443746 -0.451942  0.381275   \n",
       "coeficient__of_variation  0.043580   0.999245  0.965811 -0.983573  0.950184   \n",
       "\n",
       "                          skewness  kurtosis  quantile_25  quantile_50  \\\n",
       "mean                      0.039009  0.107496     0.445906     0.801363   \n",
       "deviation                 0.239904  0.309859    -0.378055     0.032728   \n",
       "variance                  0.195681  0.202585    -0.350086     0.047031   \n",
       "min                      -0.235444 -0.451237     0.354422    -0.040998   \n",
       "max                       0.351226  0.460183    -0.294379     0.022891   \n",
       "skewness                  1.000000  0.260637    -0.027052     0.046493   \n",
       "kurtosis                  0.260637  1.000000    -0.016196     0.116686   \n",
       "quantile_25              -0.027052 -0.016196     1.000000     0.452045   \n",
       "quantile_50               0.046493  0.116686     0.452045     1.000000   \n",
       "quantile_75               0.040409  0.154731    -0.070777     0.415262   \n",
       "coeficient__of_variation  0.244670  0.313613    -0.388945     0.005998   \n",
       "\n",
       "                          quantile_75  coeficient__of_variation  \n",
       "mean                         0.537295                  0.043580  \n",
       "deviation                    0.475736                  0.999245  \n",
       "variance                     0.443746                  0.965811  \n",
       "min                         -0.451942                 -0.983573  \n",
       "max                          0.381275                  0.950184  \n",
       "skewness                     0.040409                  0.244670  \n",
       "kurtosis                     0.154731                  0.313613  \n",
       "quantile_25                 -0.070777                 -0.388945  \n",
       "quantile_50                  0.415262                  0.005998  \n",
       "quantile_75                  1.000000                  0.458700  \n",
       "coeficient__of_variation     0.458700                  1.000000  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LANL_X.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With what we have now let's divide the data into training set and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.array(LANL_X), np.array(LANL_y), test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3356, 1)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Now let's see how well a model performs. I uses a random forest because I like them and not for anything in particular, altough later we will need to test a lot of models and select a few promising"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "classifier = RandomForestRegressor(n_estimators=1000, criterion=\"mae\", \n",
    "                                    random_state=42, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:  4.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mae', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=None,\n",
       "           oob_score=False, random_state=42, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.302571027954395"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "mean_absolute_error(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
